{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 102,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1232,
     "status": "ok",
     "timestamp": 1512501195917,
     "user": {
      "displayName": "Adithya Balaji",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116171904802361574420"
     },
     "user_tz": 480
    },
    "id": "2bOKECx7-x5s",
    "outputId": "4ad63301-24a7-4906-db6a-7486044b8e0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python2.7/dist-packages\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python2.7/dist-packages (from keras)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from keras)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python2.7/dist-packages (from keras)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python2.7/dist-packages (from keras)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1259,
     "status": "ok",
     "timestamp": 1512501197201,
     "user": {
      "displayName": "Adithya Balaji",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116171904802361574420"
     },
     "user_tz": 480
    },
    "id": "XUQh7JEA_K30",
    "outputId": "10f44ee0-5030-42fb-ee46-8f0a5be7b0d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NQFgNNYv56gU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/Adithya/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import gzip\n",
    "###\n",
    "import numpy as np\n",
    "###\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "0XBw70hE_TZV"
   },
   "outputs": [],
   "source": [
    "#function to read data row-wise\n",
    "def get_data(fn):\n",
    "  \"\"\"\n",
    "  Function to read data row-wise\n",
    "  \n",
    "  Input: \n",
    "  fn - File location as a string\n",
    "  Output: \n",
    "  data - List where each element contains the row from the data\n",
    "  \"\"\"\n",
    "  data = []\n",
    "  with open(fn) as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    data = [row for row in reader]\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "at5VpMx9Ax3M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_fields(data, fields):\n",
    "  \"\"\"\n",
    "  Function to read contents from the row and convert them into a numpy array\n",
    "  \n",
    "  Input: \n",
    "  data - List where each element contains the row from the data\n",
    "  fields - Dictionary containing the function definitions for each key in it\n",
    "  Output: \n",
    "  extracted - List of numpy arrays, each entry corresponding to a row in data\n",
    "  \"\"\"\n",
    "  #print fields\n",
    "  extracted = []\n",
    "  for row in data:\n",
    "    extract = []\n",
    "    for field, f in sorted(fields.items()):\n",
    "      #print field,f\n",
    "      info = f(row[field])\n",
    "      if type(info) == list:\n",
    "        extract.extend(info)\n",
    "      else:\n",
    "        extract.append(info)\n",
    "    extracted.append(np.array(extract, dtype=np.float32))\n",
    "  return extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(X, scaler=None):\n",
    "  if not scaler:\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "  X = scaler.transform(X)\n",
    "  return X, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "nvw65qzICUmo"
   },
   "outputs": [],
   "source": [
    "def shuffle(X, y, seed=1331):\n",
    "  '''\n",
    "  Function to shuffle the contents of lists X and y\n",
    "  based on a fixed seed\n",
    "  \n",
    "  Input: \n",
    "  X - List input\n",
    "  y - List input\n",
    "  seed - seed for shuffling\n",
    "  \n",
    "  Output: \n",
    "  Shuffled lists X and y \n",
    "  '''\n",
    "  np.random.seed(seed)\n",
    "  shuffle = np.arange(len(y))\n",
    "  np.random.shuffle(shuffle)\n",
    "  X = X[shuffle]\n",
    "  y = y[shuffle]\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "fqqwskxJDIaX"
   },
   "outputs": [],
   "source": [
    "def dating(x):\n",
    "  '''\n",
    "  Function to extract the date-time entry string into a list containing the\n",
    "  date, time elements\n",
    "  \n",
    "  Input: \n",
    "  x - String containing data and time\n",
    "  \n",
    "  Output: \n",
    "  List containing [Year, month, day, time]\n",
    "  '''\n",
    "  date, time = x.split(' ')\n",
    "  y, m, d = map(int, date.split('-'))\n",
    "  time = time.split(':')[:2]\n",
    "  time = int(time[0]) * 60 + int(time[1])\n",
    "  return [y, m, d, time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "LYgJUt4TEkgU"
   },
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', \n",
    "        'Friday', 'Saturday', 'Sunday']\n",
    "districts = ['BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION', 'NORTHERN',\n",
    "             'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN']\n",
    "labels = 'ARSON,ASSAULT,BAD CHECKS,BRIBERY,BURGLARY,DISORDERLY CONDUCT,DRIVING UNDER THE INFLUENCE,DRUG/NARCOTIC,DRUNKENNESS,EMBEZZLEMENT,EXTORTION,FAMILY OFFENSES,FORGERY/COUNTERFEITING,FRAUD,GAMBLING,KIDNAPPING,LARCENY/THEFT,LIQUOR LAWS,LOITERING,MISSING PERSON,NON-CRIMINAL,OTHER OFFENSES,PORNOGRAPHY/OBSCENE MAT,PROSTITUTION,RECOVERED VEHICLE,ROBBERY,RUNAWAY,SECONDARY CODES,SEX OFFENSES FORCIBLE,SEX OFFENSES NON FORCIBLE,STOLEN PROPERTY,SUICIDE,SUSPICIOUS OCC,TREA,TRESPASS,VANDALISM,VEHICLE THEFT,WARRANTS,WEAPON LAWS'.split(',')\n",
    "\n",
    "data_fields = {\n",
    "    'X': lambda x: float(x),\n",
    "    'Y': lambda x: float(x),\n",
    "    'DayOfWeek': lambda x: days.index(x) / float(len(days)),\n",
    "    'Address': lambda x: [1 if 'block' in x.lower() else 0],\n",
    "    'PdDistrict': lambda x: [1 if x == d else 0 for d in districts],\n",
    "    'Dates': dating,  # Parse 2015-05-13 23:53:00\n",
    "}\n",
    "\n",
    "label_fields = {'Category': lambda x: labels.index(x.replace(',', ''))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "rY3una4uFsE1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Creating training data...\n",
      "Creating training labels...\n",
      "Input dimensions: 18\n"
     ]
    }
   ],
   "source": [
    "# Loading data in the format ready for training the Neural Network\n",
    "\n",
    "print('Loading training data...')\n",
    "raw_train = get_data('./input/train.csv')\n",
    "print('Creating training data...')\n",
    "X = np.array(get_fields(raw_train, data_fields), dtype=np.float32)\n",
    "print('Creating training labels...')\n",
    "y = np.array(get_fields(raw_train, label_fields))\n",
    "del raw_train\n",
    "\n",
    "X, y = shuffle(X, y)\n",
    "X, scaler = preprocess_data(X)\n",
    "Y = np_utils.to_categorical(y)\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "output_dim = len(labels)\n",
    "print('Input dimensions: {}'.format(input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "apo4ee_YKA3q"
   },
   "outputs": [],
   "source": [
    "# Fixing hyperparameters\n",
    "EPOCHS = 1\n",
    "BATCHES = 128\n",
    "HN = 39\n",
    "RUN_FOLDS = False\n",
    "nb_folds = 4\n",
    "kfolds = KFold(len(y), nb_folds)\n",
    "av_ll = 0.\n",
    "f = 0\n",
    "# Running the model using kfold cross validation\n",
    "if RUN_FOLDS:\n",
    "  for train, valid in kfolds:\n",
    "      print('---' * 20)\n",
    "      print('Fold', f)\n",
    "      print('---' * 20)\n",
    "      f += 1\n",
    "      X_train = X[train]\n",
    "      X_valid = X[valid]\n",
    "      Y_train = Y[train]\n",
    "      Y_valid = Y[valid]\n",
    "      y_valid = y[valid]\n",
    "\n",
    "      print(\"Building model...\")\n",
    "      model = build_model(input_dim, output_dim, HN)\n",
    "\n",
    "      print(\"Training model...\")\n",
    "\n",
    "      model.fit(X_train, Y_train, nb_epoch=EPOCHS, batch_size=BATCHES, validation_data=(X_valid, Y_valid), verbose=0)\n",
    "      valid_preds = model.predict_proba(X_valid)\n",
    "      ll = metrics.log_loss(y_valid, valid_preds)\n",
    "      print(\"LL:\", ll)\n",
    "      av_ll += ll\n",
    "  print('Average LL:', av_ll / nb_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4lOSpLdUHbFs"
   },
   "outputs": [],
   "source": [
    "def build_model(input_dim, output_dim, hn=32, dp=0.5, layers=1):\n",
    "    '''\n",
    "    Function to build the convolutional nueral network with hyperparameters\n",
    "    which are given by the function call\n",
    "\n",
    "    Input: \n",
    "    input_dim - Dimensions of the input layer\n",
    "    output_dim - Dimensions of the output layer\n",
    "    hn - Number of units in the nueral network\n",
    "    dp - Dropout probabilities\n",
    "    layers - Number of layers present in the network\n",
    "    \n",
    "    Output: \n",
    "    model - Fully constructed model based on the specified parameters \n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hn,input_shape = (input_dim,),init='glorot_uniform'))\n",
    "    model.add(PReLU(input_shape=(hn,)))\n",
    "    model.add(Dropout(dp))\n",
    "\n",
    "    for i in range(layers):\n",
    "      model.add(Dense(hn, input_shape = (hn,), init='glorot_uniform'))\n",
    "      model.add(PReLU(input_shape=(hn,)))\n",
    "      model.add(BatchNormalization(input_shape=(hn,)))\n",
    "      model.add(Dropout(dp))\n",
    "\n",
    "    model.add(Dense(hn, input_shape=(output_dim,), init='glorot_uniform'))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "PfgC4-WPYhlE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating submission...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Adithya/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(39, kernel_initializer=\"glorot_uniform\", input_shape=(18,))`\n",
      "/Users/Adithya/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(39, kernel_initializer=\"glorot_uniform\", input_shape=(39,))`\n",
      "/Users/Adithya/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(39, kernel_initializer=\"glorot_uniform\", input_shape=(39,))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading testing data...\n",
      "Creating testing data...\n",
      "Predicting over testing data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating submission...\")\n",
    "\n",
    "model = build_model(input_dim, output_dim, HN)\n",
    "model.fit(X, Y, nb_epoch=EPOCHS, batch_size=BATCHES, verbose=0)\n",
    "\n",
    "print('Loading testing data...')\n",
    "raw_test = get_data('./input/test.csv')\n",
    "print('Creating testing data...')\n",
    "X_test = np.array(get_fields(raw_test, data_fields), dtype=np.float32)\n",
    "del raw_test\n",
    "X_test, _ = preprocess_data(X_test, scaler)\n",
    "\n",
    "print('Predicting over testing data...')\n",
    "preds = model.predict_proba(X_test, verbose=0)\n",
    "\n",
    "with gzip.open('sf-nn.csv.gz', 'wt') as outf:\n",
    "  fo = csv.writer(outf, lineterminator='\\n')\n",
    "  fo.writerow(['Id'] + labels)\n",
    "\n",
    "  for i, pred in enumerate(preds):\n",
    "    fo.writerow([i] + list(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Copy of Untitled0.ipynb",
   "provenance": [
    {
     "file_id": "1uDEwZjZYUkiSbguSQCrH89Z8IVoL9x2r",
     "timestamp": 1512506017662
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
